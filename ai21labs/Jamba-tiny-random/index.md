
# Jamba-tiny-random
---


## README([From Huggingface](https://huggingface.co/ai21labs/Jamba-tiny-random))



This is a tiny, dummy version of [Jamba](https://huggingface.co/ai21labs/Jamba-v0.1), used for debugging and experimentation over the Jamba architecture.

It has 128M parameters (instead of 52B), **and is initialized with random weights and did not undergo any training.**




## Model Files

- [README.md](https://paddlenlp.bj.bcebos.com/models/community/ai21labs/Jamba-tiny-random/README.md) (302.0 B)

- [config.json](https://paddlenlp.bj.bcebos.com/models/community/ai21labs/Jamba-tiny-random/config.json) (1.0 KB)

- [generation_config.json](https://paddlenlp.bj.bcebos.com/models/community/ai21labs/Jamba-tiny-random/generation_config.json) (96.0 B)

- [model.safetensors](https://paddlenlp.bj.bcebos.com/models/community/ai21labs/Jamba-tiny-random/model.safetensors) (243.5 MB)

- [sentencepiece.bpe.model](https://paddlenlp.bj.bcebos.com/models/community/ai21labs/Jamba-tiny-random/sentencepiece.bpe.model) (1.1 MB)

- [special_tokens_map.json](https://paddlenlp.bj.bcebos.com/models/community/ai21labs/Jamba-tiny-random/special_tokens_map.json) (538.0 B)

- [tokenizer_config.json](https://paddlenlp.bj.bcebos.com/models/community/ai21labs/Jamba-tiny-random/tokenizer_config.json) (1.1 KB)


[Back to Main](../../)