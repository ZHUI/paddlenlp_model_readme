
# internlm-xcomposer2-7b
---


## README([From Huggingface](https://huggingface.co/internlm/internlm-xcomposer2-7b))




<p align="center">
    <img src="logo_en.png" width="400"/>
<p>

<p align="center">
    <b><font size="6">InternLM-XComposer2</font></b> 
<p>

<div align="center">

[ğŸ’»Github Repo](https://github.com/InternLM/InternLM-XComposer)

[Paper](https://arxiv.org/abs/2401.16420)

</div>

**InternLM-XComposer2** is a vision-language large model (VLLM) based on [InternLM2](https://github.com/InternLM/InternLM) for advanced text-image comprehension and composition. 

We release InternLM-XComposer2 series in two versions:

- InternLM-XComposer2-VL: The pretrained VLLM model with InternLM2 as the initialization of the LLM, achieving strong performance on various multimodal benchmarks.
- InternLM-XComposer2: The finetuned VLLM for *Free-from Interleaved Text-Image Composition*.

### Import from Transformers
To load the InternLM-XComposer2-7B model using Transformers, use the following code:
```python
import paddle
from PIL import Image
from paddlenlp.transformers import AutoTokenizer, AutoModelForCausalLM
ckpt_path = "internlm/internlm-xcomposer2-7b"
tokenizer = AutoTokenizer.from_pretrained(ckpt_path, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(ckpt_path, dtype=paddle.float32, trust_remote_code=True).cuda()
# Set `dtype=paddle.float16` to load model in float16, otherwise it will be loaded as float32 and might cause OOM Error.
# model = AutoModelForCausalLM.from_pretrained(ckpt_path, dtype=paddle.float16, trust_remote_code=True).cuda()
model = model.eval()
img_path_list = [
    './panda.jpg',
    './bamboo.jpeg',
]
images = []
for img_path in img_path_list:
    image = Image.open(img_path).convert("RGB")
    image = model.vis_processor(image)
    images.append(image)
image = paddle.stack(images)
query = '<ImageHere> <ImageHere>please write an article based on the images. Title: my favorite animal.'
with torch.cuda.amp.autocast():
    response, history = model.chat(tokenizer, query=query, image=image, history=[], do_sample=False)
print(response)
""""
# My favorite animal is the panda. Pandas are one of the most popular animals in the world, and for good reason. They are adorable, cuddly creatures that have captured the hearts of people all over the globe.
Pandas are native to China and can be found in the wild in a few specific regions. However, they are also very popular in captivity, with many zoos around the world housing pandas as part of their exhibits. I have been fortunate enough to see pandas up close at several different zoos, and each time it was an amazing experience.
One thing that always strikes me about pandas is how much they love to eat bamboo. In fact, pandas spend almost all of their waking hours eating bamboo. This may not seem like a lot of fun, but pandas actually enjoy munching on this tough plant. It's fascinating to watch them chew through the tough stalks and leaves, and then lick their lips in satisfaction.
Another thing that I find interesting about pandas is their black and white fur. The combination of these two colors creates a striking contrast that makes pandas instantly recognizable. In addition, the black patches on their face give them a unique expression that seems to convey both playfulness and seriousness.
Despite their popularity, pandas do face some challenges. Their habitat is being destroyed by human activities such as logging and agriculture, which has led to a decline in their population. Additionally, pandas are considered endangered due to factors such as low reproductive rates and limited genetic diversity.
However, there are efforts underway to protect pandas and their habitats. Many organizations work to raise awareness about the importance of preserving these beautiful creatures, and governments in countries where pandas live are taking steps to conserve their natural environment.
In conclusion, pandas are truly remarkable animals that deserve our admiration and protection. With their distinctive appearance, playful personalities, and love of bamboo, it's no wonder that pandas have become so beloved around the world. Let's do what we can to ensure that future generations can continue to appreciate these wonderful creatures.
"""
```

### é€šè¿‡ Transformers åŠ è½½
é€šè¿‡ä»¥ä¸‹çš„ä»£ç åŠ è½½ InternLM-XComposer2-7B æ¨¡å‹

```python
import paddle
from PIL import Image
from paddlenlp.transformers import AutoTokenizer, AutoModelForCausalLM
ckpt_path = "internlm/internlm-xcomposer2-7b"
tokenizer = AutoTokenizer.from_pretrained(ckpt_path, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(ckpt_path, dtype=paddle.float32, trust_remote_code=True).cuda()
# `dtype=paddle.float16` å¯ä»¥ä»¤æ¨¡å‹ä»¥ float16 ç²¾åº¦åŠ è½½ï¼Œå¦åˆ™ transformers ä¼šå°†æ¨¡å‹åŠ è½½ä¸º float32ï¼Œå¯¼è‡´æ˜¾å­˜ä¸è¶³
# model = AutoModelForCausalLM.from_pretrained(ckpt_path, dtype=paddle.float16, trust_remote_code=True).cuda()
model = model.eval() 
img_path_list = [
    './panda.jpg',
    './bamboo.jpeg',
]
images = []
for img_path in img_path_list:
    image = Image.open(img_path).convert("RGB")
    image = model.vis_processor(image)
    images.append(image)
image = paddle.stack(images)
query = '<ImageHere> <ImageHere>è¯·æ ¹æ®å›¾ç‰‡å†™ä¸€ç¯‡ä½œæ–‡ï¼šæˆ‘æœ€å–œæ¬¢çš„å°åŠ¨ç‰©ã€‚è¦æ±‚ï¼šé€‰å‡†è§’åº¦ï¼Œç¡®å®šç«‹æ„ï¼Œæ˜ç¡®æ–‡ä½“ï¼Œè‡ªæ‹Ÿæ ‡é¢˜ã€‚'
with torch.cuda.amp.autocast():
    response, history = model.chat(tokenizer, query=query, image=image, history=[], do_sample=False)
print(response)
"""
# æˆ‘æœ€å–œæ¬¢çš„å°åŠ¨ç‰©
æˆ‘å–œæ¬¢çš„åŠ¨ç‰©æœ‰å¾ˆå¤šï¼Œæœ‰æ´»æ³¼å¯çˆ±çš„å°ç‹—ã€ç¾ä¸½é«˜è´µçš„å­”é›€ã€å‡¶çŒ›çš„ç‹®å­â€¦â€¦ä½†æˆ‘æœ€å–œæ¬¢çš„æ˜¯æ†¨æ€å¯æ¬çš„å¤§ç†ŠçŒ«ã€‚
å¤§ç†ŠçŒ«æ˜¯å›½å®ï¼Œå®ƒæœ‰ç€é»‘ç™½ç›¸é—´çš„æ¯›è‰²ï¼Œåœ†æ»šæ»šçš„èº«ä½“ï¼Œèƒ–ä¹ä¹çš„æ‰‹è„šï¼Œå¤§å¤§çš„çœ¼ç›å’ŒçŸ­çŸ­çš„å°¾å·´ã€‚å®ƒçš„è€³æœµå°å°çš„ï¼Œåƒä¸¤ç‰‡æ ‘å¶ï¼›å˜´å·´åˆå®½åˆæ‰ï¼Œå°±åƒä¸€ä¸ªâ€œæœˆç‰™â€ï¼›å››è‚¢çŸ­å°ç²—å£®ï¼Œèµ°èµ·è·¯æ¥æ‘‡æ‘‡æ™ƒæ™ƒï¼Œéå¸¸å¯çˆ±ã€‚
å¤§ç†ŠçŒ«å–œæ¬¢åƒç«¹å­ï¼Œæ¯å¤©è¦åƒ30å¤šæ–¤å‘¢ï¼å®ƒä»¬åƒç«¹å­çš„æ ·å­å¾ˆç‰¹åˆ«ï¼Œå…ˆæŠŠç«¹å­å’¬æ–­ï¼Œç„¶åæŠ±ç€ç«¹å­å•ƒèµ·æ¥ï¼Œæœ‰æ—¶è¿˜ä¼šæŠŠç«¹å­æ‰”åˆ°ç©ºä¸­å†æ¥ä½ç»§ç»­å•ƒï¼Œå¥½åƒåœ¨è¡¨æ¼”æ‚æŠ€ä¸€æ ·ã€‚åƒé¥±äº†ä»¥åï¼Œå®ƒä»¬å°±æ‡’æ´‹æ´‹åœ°èººåœ¨åœ°ä¸Šç¡å¤§è§‰ï¼ŒçœŸæ˜¯ä¸ªåå‰¯å…¶å®çš„â€œå¤§æ‡’çŒ«â€å•Šï¼
å¤§ç†ŠçŒ«ä¸ä»…çˆ±åƒç«¹å­ï¼Œè¿˜çˆ±ç¡è§‰ã€‚ä¸€å¤©ä¸­ï¼Œé™¤äº†åƒé¥­çš„æ—¶é—´ï¼Œå…¶ä»–æ—¶é—´éƒ½åœ¨ç¡è§‰ã€‚æœ‰æ—¶å€™ï¼Œå®ƒä»¬ä¼šçˆ¬ä¸Šæ ‘ï¼Œååœ¨æ ‘æä¸Šå‘¼å‘¼å¤§ç¡ï¼›æœ‰æ—¶å€™ï¼Œå®ƒä»¬ä¼šæ‰¾ä¸€ä¸ªé˜´å‡‰çš„åœ°æ–¹ï¼Œèººä¸‹æ¥ç¾ç¾åœ°ç¡ä¸Šä¸€è§‰ã€‚
å¤§ç†ŠçŒ«è¿˜æ˜¯ä¸€ç§æ¿’å±åŠ¨ç‰©ï¼Œå› ä¸ºå®ƒä»¬çš„æ –æ¯åœ°è¢«ç ´åï¼Œé£Ÿç‰©å‡å°‘ï¼Œæ•°é‡è¶Šæ¥è¶Šå°‘ã€‚ä¸ºäº†ä¿æŠ¤å¤§ç†ŠçŒ«ï¼Œäººä»¬å»ºç«‹äº†å¤§ç†ŠçŒ«ä¿æŠ¤åŒºï¼Œç¦æ­¢ç ä¼æ ‘æœ¨ï¼Œè®©å¤§ç†ŠçŒ«æœ‰ä¸€ä¸ªå®‰å…¨çš„å®¶ã€‚
æˆ‘å–œæ¬¢å¤§ç†ŠçŒ«ï¼Œå› ä¸ºå®ƒæ—¢å¯çˆ±åˆçè´µï¼Œæˆ‘å¸Œæœ›å®ƒèƒ½ä¸€ç›´ç”Ÿæ´»åœ¨æˆ‘ä»¬çš„åœ°çƒä¸Šï¼Œé™ªä¼´ç€æˆ‘ä»¬æˆé•¿ã€‚
"""
```

### Open Source License
The code is licensed under Apache-2.0, while model weights are fully open for academic research and also allow free commercial usage. To apply for a commercial license, please fill in the application form (English)/ç”³è¯·è¡¨ï¼ˆä¸­æ–‡ï¼‰. For other questions or collaborations, please contact internlm@pjlab.org.cn.




## Model Files

- [README.md](https://paddlenlp.bj.bcebos.com/models/community/internlm/internlm-xcomposer2-7b/README.md) (7.1 KB)

- [config.json](https://paddlenlp.bj.bcebos.com/models/community/internlm/internlm-xcomposer2-7b/config.json) (1.1 KB)

- [generation_config.json](https://paddlenlp.bj.bcebos.com/models/community/internlm/internlm-xcomposer2-7b/generation_config.json) (175.0 B)

- [model_state.pdparams](https://paddlenlp.bj.bcebos.com/models/community/internlm/internlm-xcomposer2-7b/model_state.pdparams) (32.3 GB)

- [sentencepiece.bpe.model](https://paddlenlp.bj.bcebos.com/models/community/internlm/internlm-xcomposer2-7b/sentencepiece.bpe.model) (1.4 MB)

- [special_tokens_map.json](https://paddlenlp.bj.bcebos.com/models/community/internlm/internlm-xcomposer2-7b/special_tokens_map.json) (95.0 B)

- [tokenizer_config.json](https://paddlenlp.bj.bcebos.com/models/community/internlm/internlm-xcomposer2-7b/tokenizer_config.json) (401.0 B)


[Back to Main](../../)